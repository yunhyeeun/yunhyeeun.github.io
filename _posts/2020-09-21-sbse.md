---
title: SBSE(Search-Based Software Engineering)
categories: 
    - Develop
tags:
    - sbse
    - study
---
***

Search Based Software Enginnering

> Meta-heuristic : strategies that guide the search of the acceptable solution

metaheuristic이면 특정 문제에 국한되지 않고 solution을 찾는 기술이라고 생각하면 된다.   

게임을 예시로 생각해보자.   
무슨 게임을 하든 보통 사람은 스테이지를 한 번에 클리어를 못한다.   
몇 번의 시행착오를 거쳐야 한다.   
그리고 게임을 하기 전에 메뉴얼을 꼼꼼히 다 읽고 시작하는 사람도 없다.   
그냥 다들 무작정 start 버튼을 누르지 않나..?   

슈퍼마리오 게임을 하다가 구멍에 떨어져 죽었다면 다음 trial에서는 점프하는 순간이나 위치를 조금 수정해서 시도해볼 것이다.   
그러니까 몇번 죽어봐야 스테이지를 클리어하는 느낌이다.   

이런 상황에서 아이디어를 갖고와보자.   

1. **representation** : 이번에는 무엇을 시도해볼까?   
2. **operator** : 이전 trial과는 어떻게 다르게 시도해볼까?   
3. **fitness function** : 이번에는 얼마나 잘했는가?   

이 세가지를 슈퍼마리오에 대입해보자.   

1. representation : (점프 키, 점프 시작 시간, 점프 시작 위치)   
2. operator : 점프 시작 시간이나 위치를 증가/감소, 점프 키 대신 공격 키로 치환   
3. fitness function : 죽기 직전까지 이동한 거리   

## Fitness Landscape

우리가 optimisation을 할 때 잘 하고 있는지 눈으로 확인하기 어렵다.   
하지만 가능만 하다면 매우 유용하다.   
solution space(S)와 fitness function(F)가 주어질 때, fitness landscape는 **F: S -> R의 hyper dimensional surface**이다.   

여기 문제가 하나 있다.   

0 <= x <= 10, 0 <= y <= 10 일 때, x + y = 10을 만족하는 (x, y) 쌍을 찾으시오.   

여기서 solution space는 다음과 같다.   

![solution space](/assets/images/sbse-1.png)

그럼 문제에서 fitness function은 어떻게 정의할 수 있을까?   

fitness function은 이번 trial이 얼마나 좋은지 판단하는 역할을 한다.   
따라서 다음과 같이 정의할 수 있다.   

$$   
f(x, y) = |10 - (x + y)|   
$$
<br>

여기서는 fitness function이 minimize할수록 solution에 가깝다.   
Fitness landscape 다음과 같다.   

![fitness landscape](/assets/images/sbse-2.png)

fitness landscape 모양을 보면 optimisation을 직관적으로 확인할 수 있다.   
좋지 않은 fitness landscape를 몇 개 알아보자.   

### Plateau   

평지를 말한다. 여러 trial 결과가 평지 안에 있다면 escape이 어렵다.   

![plateau](/assets/images/sbse-3.png)

### Needle

바늘처럼 생겼다. search 자체가 힘들다.   
이는 fitness function나 문제 자체를 개선하면 고칠 수 있다.   

![needle](/assets/images/sbse-4.png)

### Ruggedness

굴곡이 많으면 local optima가 많다는 이야기다.   
다시 말해 global optima를 찾기 어렵다는 뜻이다.   

![ruggedness](/assets/images/sbse-5.png)


## Random Search

metaheruistic처럼 non-deterministic한 search 방법이다.   
Random solution을 만들고 이전 fitness와 비교해서 더 좋은 것을 남겨둔다.   

만들기 쉽고, automatable하고, unbiased하다.   
그러나 효율성이 떨어질 수 있다.

가장 큰 특징은 **guidance가 없다**는 것이다.   
따라서 항상 default sanity check인데 내가 구현한 search가 random search보다 좋지 못하면 문제가 있는거다.   
그래서 guidance가 없는 문제를 풀 때 유용하게 쓰인다.   
가령 프로그램이 crash되는 input을 찾는 문제 같은 거.

## Local Search

다시 fitness landscape로 돌아가서, fitness landscape를 만들었다면 optimisation을 어떻게 할까?   

우선 single random solution에서 시작한다.   
그 다음 근처 solution과 비교하면서 더 좋은 solution으로 이동한다.   
더 좋은 solution이 없을 때까지 반복한다.   
Hill climbing algorithm으로 불리기도 한다.   

![hill climbing](/assets/images/sbse-6.png)

다음 solution으로 넘어갈 때 가장 좋은 solution으로 넘어갈 수도 있지만 가장 처음이나 random하게 넘어갈 수도 있다.   
어떤 방법이 더 좋은지는 아무도 알 수 없다.   
어떤 방법은 택하든 hill climbing은 절대 밑으로 내려가지 않는다.   

Hill climbing의 가장 큰 문제는 local optima를 벗어날 수 없다는 것이다.   
우리가 지금 있는 위치가 local optimum인지 global optimum인지도 모르고 언제 optimisation을 멈춰야할지 알 수가 없다.   

**Annealing** 개념을 도입해보자.   
Annealing은 철강을 만들 때 사용하는 기법이다.   
철을 고온으로 오래 유지하다가 서서히 온도를 낮춘다.   
이렇게 만들어진 철은 제련하기 쉬워진다.   

우리도 고온에서 시작해서 서서히 온도를 낮춰보자.   
온도가 높을 때, solution은 불안정하기 때문에 random move를 통해 escape하기 쉽게 만든다.   
온도가 내려가면서 escape하는 빈도는 서서히 줄어들 것이다.   

![simulated annealing](/assets/images/sbse-7.png)

그림에서 P 함수가 조금 다른 것을 볼 수 있다.   
new solution이 더 나쁠 때 이상한 값을 return한다.   
이는 **acceptance probability**이다.   
new solution이 이전 것보다 더 좋거나 같으면 새 것을 무조건 선택한다.   
그러나 그렇지 않다면, small downhill movement로 유도한다.   
이는 온도가 낮을수록 더 작은 값을 가진다.   

![acceptance probability](/assets/images/sbse-8.png)

## Search Radius

Local search를 효율적으로 쓰려면, search space는 크더라도 search radius는 작아야한다.   
Search radius는 search space를 가로지를 때 필요한 move 수이다.   

TSP(Traveling Salesman Problem)을 예로 들어보자.   
Search space는 N!이다.   
Search radius는 N(N-1) / 2이다.
